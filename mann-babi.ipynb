{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANNs for bAbI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torch.nn import functional as F, Embedding, Linear, Module, Parameter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Statement(object):\n",
    "    def __init__(self, slot, text):\n",
    "        self.slot = slot\n",
    "        self.text = text\n",
    "    \n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        return Statement(self.slot, text)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'S[{0.slot:02d}](text={0.text})'.format(self)\n",
    "\n",
    "\n",
    "class Query(object):\n",
    "    def __init__(self, slot, text, answer, refs):\n",
    "        self.slot = slot\n",
    "        self.text = text\n",
    "        self.answer = answer\n",
    "        self.refs = refs\n",
    "\n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        answer = Variable(LongTensor([d[i] for i in self.answer]))\n",
    "        return Query(self.slot, text, answer, list(self.refs))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Q[{0.slot:02d}](text={0.text}, answer={0.answer}, refs={0.refs})'.format(self)\n",
    "\n",
    "\n",
    "class TaskData(object):\n",
    "    def __init__(self, task, data_dir='babi-tasks_1-20_v1-2/en/'):\n",
    "        self.task = task\n",
    "        def match_one_file(p):\n",
    "            ms = [f for f in os.listdir(data_dir) if re.match(p, f)]\n",
    "            if len(ms) != 1:\n",
    "                raise ValueError('{} matched the wrong number of items: {}'.format(p, ms))\n",
    "            return os.path.join(data_dir, ms[0])\n",
    "\n",
    "        self.train_file = match_one_file(r'qa{}_.*_train.txt'.format(task))\n",
    "        with open(self.train_file) as fp:\n",
    "            self.train = self.parse(fp)\n",
    "\n",
    "        self.test_file = match_one_file(r'qa{}_.*_test.txt'.format(task))\n",
    "        with open(self.test_file) as fp:\n",
    "            self.test = self.parse(fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse(lines):\n",
    "        prev_slot = None\n",
    "        episodes = [[]]\n",
    "        for line in lines:\n",
    "            slot, text = line.lower().strip().split(' ', 1)\n",
    "            slot = int(slot)\n",
    "            if '\\t' in text:\n",
    "                text, answer, refs = [re.findall(r'\\w+', s) for s in text.split('\\t')]\n",
    "                refs = [int(ref) for ref in refs]\n",
    "                item = Query(slot, text, answer, refs)\n",
    "            else:\n",
    "                text = re.findall(r'\\w+', text)\n",
    "                item = Statement(slot, text)\n",
    "            if prev_slot is None or slot >  prev_slot:\n",
    "                episodes[-1].append(item)\n",
    "            else:\n",
    "                episodes.append([item])\n",
    "            prev_slot = slot\n",
    "        return episodes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'TaskData(task={}, num_train={}, num_test={})'.format(self.task, len(self.train), len(self.test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskData(task=16, num_train=1000, num_test=1000)\n",
      "  train_file = babi-tasks_1-20_v1-2/en/qa16_basic-induction_train.txt\n",
      "  test_file  = babi-tasks_1-20_v1-2/en/qa16_basic-induction_test.txt\n",
      "\n",
      "S[01](text=['lily', 'is', 'a', 'frog'])\n",
      "S[02](text=['bernhard', 'is', 'a', 'frog'])\n",
      "S[03](text=['bernhard', 'is', 'green'])\n",
      "S[04](text=['brian', 'is', 'a', 'lion'])\n",
      "S[05](text=['brian', 'is', 'white'])\n",
      "S[06](text=['julius', 'is', 'a', 'swan'])\n",
      "S[07](text=['julius', 'is', 'green'])\n",
      "S[08](text=['lily', 'is', 'green'])\n",
      "S[09](text=['greg', 'is', 'a', 'swan'])\n",
      "Q[10](text=['what', 'color', 'is', 'greg'], answer=['green'], refs=[9, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "data = TaskData(16)\n",
    "print(data)\n",
    "print('  train_file =', data.train_file)\n",
    "print('  test_file  =', data.test_file)\n",
    "print()\n",
    "for x in data.train[0]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab\n",
      "0 => lily\n",
      "1 => is\n",
      "2 => a\n",
      "3 => frog\n",
      "4 => bernhard\n",
      "5 => green\n",
      "6 => brian\n",
      "7 => lion\n",
      "8 => white\n",
      "9 => julius\n",
      "10 => swan\n",
      "11 => greg\n",
      "12 => what\n",
      "13 => color\n",
      "14 => rhino\n",
      "15 => gray\n",
      "16 => yellow\n"
     ]
    }
   ],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "for episode in data.train + data.test:\n",
    "    for item in episode:\n",
    "        for word in item.text + (item.answer if isinstance(item, Query) else []):\n",
    "            try:\n",
    "                i = word2id[word]\n",
    "            except KeyError:\n",
    "                word2id[word] = len(word2id)\n",
    "                id2word[word2id[word]] = word\n",
    "print('Vocab')\n",
    "for i, word in sorted(id2word.items()):\n",
    "    print(i, '=>', word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Network\n",
    "\n",
    "### Update\n",
    "$\\begin{align*}\n",
    "    v &= Ax_t \\\\\n",
    "    z &= \\sigma(W_a v + b_a) \\\\\n",
    "    s_t &= \\text{lstm}(v, s_{t-1}) \\\\\n",
    "    g &= \\text{softmax}(W_g s_t^h + b_g) \\\\\n",
    "    m_{i,t} &= g_i \\cdot z + (1 - g_i) * m_{i,t-1}\n",
    "\\end{align*}$\n",
    "\n",
    "### Answer\n",
    "$\\begin{align*}\n",
    "    v &= Aq_t \\\\\n",
    "    k &= \\sigma(W_k v + b_k) \\\\\n",
    "    g_i &= \\frac{k^T m_{i,t}}{||k||\\cdot||m_{i,t-1}||} \\\\\n",
    "    h_t &= \\sum_i g_i \\cdot m_{i,t-1}\n",
    "\\end{align*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.w = Parameter(FloatTensor(n_in + n_out, 4 * n_out))\n",
    "        self.b = Parameter(FloatTensor(1, 4 * n_out))\n",
    "        self.h0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.c0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.w.data.normal_(0, 0.01)\n",
    "        self.b.data.zero_()\n",
    "        self.h0.data.zero_()\n",
    "        self.c0.data.zero_()\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self.h0, self.c0\n",
    "    \n",
    "    def observable(self, s):\n",
    "        return s[0]\n",
    "    \n",
    "    def step(self, x, s=None):\n",
    "        h_prev, c_prev = s or self.initial_state\n",
    "        z = torch.cat([x, h_prev], 1)\n",
    "        a = z.mm(self.w) + self.b.expand(x.size(0), self.b.size(1))\n",
    "        i, f, o, g = torch.chunk(a, 4, dim=1)\n",
    "        i = F.sigmoid(i)\n",
    "        f = F.sigmoid(f)\n",
    "        o = F.sigmoid(o)\n",
    "        g = F.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * c\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self, n_words, embed_dim, controller_hid_dim, register_dim, n_registers):\n",
    "        super(RegNet, self).__init__()\n",
    "        self.n_words = n_words\n",
    "        self.embed_dim = embed_dim\n",
    "        self.controller_hid_dim = controller_hid_dim\n",
    "        self.register_dim = register_dim\n",
    "        self.n_registers = n_registers\n",
    "        \n",
    "        self.embedding = Embedding(n_words, embed_dim)\n",
    "        self.candidate = Linear(embed_dim, register_dim)\n",
    "        self.controller = LSTM(embed_dim, controller_hid_dim)\n",
    "        self.attend = Linear(controller_hid_dim, n_registers)\n",
    "        self.read_key = Linear(embed_dim, register_dim)\n",
    "        self.output = Linear(register_dim, n_words)\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        memory = [Variable(torch.zeros(1, self.register_dim)) for i in range(self.n_registers)]\n",
    "        return (memory, self.controller.initial_state)\n",
    "    \n",
    "    def embed(self, x):\n",
    "        return self.embedding(x).sum(0)\n",
    "    \n",
    "    def update(self, x, state=None):\n",
    "        m, s = state or self.initial_state\n",
    "        v = self.embed(x)\n",
    "        z = F.sigmoid(self.candidate(v))\n",
    "        s = self.controller.step(v, s)\n",
    "        g = F.softmax(self.attend(self.controller.observable(s)))\n",
    "        g = [gi.expand(z.size()) for gi in g.chunk(self.n_registers, dim=1)]\n",
    "        m = [g[i] * z + (1 - g[i]) * m[i] for i in range(self.n_registers)]\n",
    "        return m, s\n",
    "    \n",
    "    def scores(self, x, s=None):\n",
    "        m, _ = s or self.initial_state\n",
    "        v = self.embed(x)\n",
    "        k = self.read_key(v)\n",
    "        k_norm = k.norm()\n",
    "        g = [m[i].dot(k) / (m[i].norm() * k_norm) for i in range(self.n_registers)]\n",
    "        g = [g[i].unsqueeze(0).expand(m[i].size()) for i in range(self.n_registers)]\n",
    "#         g = [(m[i] * k).sum(1) / (m[i].norm() * k_norm) for i in range(self.n_registers)]\n",
    "#         g = F.softmax(torch.stack(g).squeeze().t()).chunk(self.n_registers, 1)\n",
    "        h = sum(g[i].expand(m[i].size()) * m[i] for i in range(self.n_registers))\n",
    "        return self.output(h)\n",
    "        \n",
    "    def unfold(self, xs):\n",
    "        s = self.initial_state\n",
    "        ss = []\n",
    "        ps = []\n",
    "        for x in xs:\n",
    "            if isinstance(x, Statement):\n",
    "                s = self.update(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(None)\n",
    "            elif isinstance(x, Query):\n",
    "                p = self.scores(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(p)\n",
    "            else:\n",
    "                raise TypeError('expected Statement or Query, got {}'.format(type(x)))\n",
    "        return ps, ss\n",
    "\n",
    "    def is_output(self, p, x):\n",
    "        if p is None:\n",
    "            assert isinstance(x, Statement)\n",
    "            return False\n",
    "        assert isinstance(x, Query)\n",
    "        return True\n",
    "    \n",
    "    def answer_cost(self, p, x):\n",
    "        return F.cross_entropy(p, x.answer)\n",
    "    \n",
    "    def cost(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return sum(self.answer_cost(p, x) \n",
    "                   for p, x in zip(ps, xs) \n",
    "                       if self.is_output(p, x))\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return [p.data.numpy().argmax(1) \n",
    "                if self.is_output(p, x) \n",
    "                else None \n",
    "                for p, x in zip(ps, xs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regnet = RegNet(len(word2id), 20, 15, 20, 5)\n",
    "opt = torch.optim.SGD(regnet.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1000\n",
      "1528.01190928\n",
      "1324.85786232\n",
      "1256.07790552\n",
      "1200.66384088\n",
      "1182.84560367\n",
      "1170.09475642\n",
      "1153.78504046\n",
      "1154.36563838\n",
      "1145.14568537\n",
      "1139.93336801\n",
      "1134.16952732\n",
      "1137.06689192\n",
      "1130.83015932\n",
      "1123.51893623\n",
      "1119.56539039\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-98893b998370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mnll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         opt.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-2fdbafe3849e>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         return sum(self.answer_cost(p, x) \n\u001b[1;32m    113\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-2fdbafe3849e>\u001b[0m in \u001b[0;36munfold\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-2fdbafe3849e>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/nn/_functions/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# cuBLAS doesn't support 0 strides in sger, so we can't use expand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = [[x.torchify(word2id) for x in xs] for xs in data.train]\n",
    "print('Number of samples:', len(data_train))\n",
    "while True:\n",
    "    random.shuffle(data_train)\n",
    "    sum_nll = 0.0\n",
    "    for xs in data_train:\n",
    "        regnet.zero_grad()\n",
    "        nll = regnet.cost(xs)\n",
    "        nll.backward()\n",
    "#         opt.step()\n",
    "        for param in regnet.parameters():\n",
    "            param.data.add_(-0.005, param.grad.data)\n",
    "        sum_nll += nll.data.numpy()[0]\n",
    "    print(sum_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S[01](text=['lily', 'is', 'a', 'swan']) None\n",
      "S[02](text=['bernhard', 'is', 'a', 'lion']) None\n",
      "S[03](text=['greg', 'is', 'a', 'swan']) None\n",
      "S[04](text=['bernhard', 'is', 'white']) None\n",
      "S[05](text=['brian', 'is', 'a', 'lion']) None\n",
      "S[06](text=['lily', 'is', 'gray']) None\n",
      "S[07](text=['julius', 'is', 'a', 'rhino']) None\n",
      "S[08](text=['julius', 'is', 'gray']) None\n",
      "S[09](text=['greg', 'is', 'gray']) None\n",
      "Q[10](text=['what', 'color', 'is', 'brian'], answer=['white'], refs=[5, 2, 4])\n",
      "(['white'], [8]) (['gray'], array([15]))\n",
      "S[01](text=['lily', 'is', 'a', 'rhino']) None\n",
      "S[02](text=['brian', 'is', 'a', 'swan']) None\n",
      "S[03](text=['bernhard', 'is', 'a', 'swan']) None\n",
      "S[04](text=['lily', 'is', 'gray']) None\n",
      "S[05](text=['brian', 'is', 'white']) None\n",
      "S[06](text=['bernhard', 'is', 'white']) None\n",
      "S[07](text=['julius', 'is', 'a', 'frog']) None\n",
      "S[08](text=['julius', 'is', 'white']) None\n",
      "S[09](text=['greg', 'is', 'a', 'frog']) None\n",
      "Q[10](text=['what', 'color', 'is', 'greg'], answer=['white'], refs=[9, 7, 8])\n",
      "(['white'], [8]) (['white'], array([8]))\n"
     ]
    }
   ],
   "source": [
    "for i, xs in enumerate(data.test):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    xs_vars = [x.torchify(word2id) for x in xs]\n",
    "    ps = regnet.predict(xs_vars)\n",
    "    assert(len(ps) == len(xs))\n",
    "    for x, p in zip(xs, ps):\n",
    "        if p is None:\n",
    "            print(x, None)\n",
    "        else:\n",
    "            print(x)\n",
    "            print((x.answer, [word2id[w] for w in x.answer]),\n",
    "                  ([id2word[j] for j in p.tolist()], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(ds):\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for xs in ds:\n",
    "        xs_vars = [x.torchify(word2id) for x in xs]\n",
    "        ps = regnet.predict(xs_vars)\n",
    "        assert(len(ps) == len(xs))\n",
    "        for x, p in zip(xs, ps):\n",
    "            if p is not None:\n",
    "                if x.answer != [id2word[i] for i in p.tolist()]:\n",
    "                    errors += 1\n",
    "                total += 1\n",
    "    return errors, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.529 (529 of 1000)\n"
     ]
    }
   ],
   "source": [
    "err, num = compute_error(data.test)\n",
    "print('error: {:0.03f} ({} of {})'.format(err / num, err, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = Variable containing:\n",
      " 1.0152 -1.2493 -0.0987\n",
      " 1.1050  0.3949 -0.6933\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "s = Variable containing:\n",
      " 0.0581  0.6610  0.0723  0.1448  0.0638\n",
      " 0.1228  0.1073  0.1913  0.0773  0.5014\n",
      "[torch.FloatTensor of size 2x5]\n",
      "\n",
      "m[0] = Variable containing:\n",
      " 0.6267  1.3359 -0.2588\n",
      "-1.1040  0.0640  0.0412\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "d1[0] = Variable containing:\n",
      "-1.0072\n",
      "-1.2232\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[0] = Variable containing:\n",
      " 0.0581\n",
      " 0.1228\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "m[1] = Variable containing:\n",
      " 0.9208  1.0184  0.5933\n",
      "-0.8441 -0.1000 -1.1692\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "d1[1] = Variable containing:\n",
      "-0.3960\n",
      "-0.1616\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[1] = Variable containing:\n",
      " 0.6610\n",
      " 0.1073\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "m[2] = Variable containing:\n",
      " 0.2443 -0.2024  0.4426\n",
      "-0.9661 -2.4098 -0.4936\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "d1[2] = Variable containing:\n",
      " 0.4571\n",
      "-1.6769\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[2] = Variable containing:\n",
      " 0.0723\n",
      " 0.1913\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "m[3] = Variable containing:\n",
      " 0.5906 -0.4106 -0.2983\n",
      "-1.3813 -0.2335 -1.0376\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "d1[3] = Variable containing:\n",
      " 1.1420\n",
      "-0.8992\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[3] = Variable containing:\n",
      " 0.1448\n",
      " 0.0773\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "m[4] = Variable containing:\n",
      "-1.3257  1.0604 -0.6917\n",
      "-0.9416  0.0404  0.7763\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "d1[4] = Variable containing:\n",
      "-2.6023\n",
      "-1.5627\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[4] = Variable containing:\n",
      " 0.0638\n",
      " 0.5014\n",
      "[torch.FloatTensor of size 2x1]\n",
      "\n",
      "g[0] = Variable containing:\n",
      " 0.0581  0.0581  0.0581\n",
      " 0.1228  0.1228  0.1228\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "R = range(5)\n",
    "k = Variable(FloatTensor(np.random.normal(0, 1, (2, 3))))\n",
    "m = [Variable(FloatTensor(np.random.normal(0, 1, (2, 3)))) for i in R]\n",
    "d = [(m[i] * k).sum(1) for i in R]\n",
    "s = F.softmax(torch.stack(d2).squeeze().t())\n",
    "g = s.chunk(5, 1)\n",
    "print('k =', k)\n",
    "print('s =', s)\n",
    "for i in R:\n",
    "    print('m[{}] = {}'.format(i, m[i]))\n",
    "    print('d1[{}] = {}'.format(i, d[i]))\n",
    "    print('g[{}] = {}'.format(i, g[i]))\n",
    "print('g[0] =', g[0].expand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
