{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANNs for bAbI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor, LongTensor\n",
    "from torch.nn import functional as F, Embedding, Linear, Module, Parameter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Statement(object):\n",
    "    def __init__(self, slot, text):\n",
    "        self.slot = slot\n",
    "        self.text = text\n",
    "    \n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        return Statement(self.slot, text)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'S[{0.slot:02d}](text={0.text})'.format(self)\n",
    "\n",
    "\n",
    "class Query(object):\n",
    "    def __init__(self, slot, text, answer, refs):\n",
    "        self.slot = slot\n",
    "        self.text = text\n",
    "        self.answer = answer\n",
    "        self.refs = refs\n",
    "\n",
    "    def torchify(self, d):\n",
    "        text = Variable(LongTensor([d[i] for i in self.text]))\n",
    "        answer = Variable(LongTensor([d[i] for i in self.answer]))\n",
    "        return Query(self.slot, text, answer, list(self.refs))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Q[{0.slot:02d}](text={0.text}, answer={0.answer}, refs={0.refs})'.format(self)\n",
    "\n",
    "\n",
    "class TaskData(object):\n",
    "    def __init__(self, task, data_dir='babi-tasks_1-20_v1-2/en/'):\n",
    "        self.task = task\n",
    "        def match_one_file(p):\n",
    "            ms = [f for f in os.listdir(data_dir) if re.match(p, f)]\n",
    "            if len(ms) != 1:\n",
    "                raise ValueError('{} matched the wrong number of items: {}'.format(p, ms))\n",
    "            return os.path.join(data_dir, ms[0])\n",
    "\n",
    "        self.train_file = match_one_file(r'qa{}_.*_train.txt'.format(task))\n",
    "        with open(self.train_file) as fp:\n",
    "            self.train = self.parse(fp)\n",
    "\n",
    "        self.test_file = match_one_file(r'qa{}_.*_test.txt'.format(task))\n",
    "        with open(self.test_file) as fp:\n",
    "            self.test = self.parse(fp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse(lines):\n",
    "        prev_slot = None\n",
    "        episodes = [[]]\n",
    "        for line in lines:\n",
    "            slot, text = line.lower().strip().split(' ', 1)\n",
    "            slot = int(slot)\n",
    "            if '\\t' in text:\n",
    "                text, answer, refs = [re.findall(r'\\w+', s) for s in text.split('\\t')]\n",
    "                refs = [int(ref) for ref in refs]\n",
    "                item = Query(slot, text, answer, refs)\n",
    "            else:\n",
    "                text = re.findall(r'\\w+', text)\n",
    "                item = Statement(slot, text)\n",
    "            if prev_slot is None or slot >  prev_slot:\n",
    "                episodes[-1].append(item)\n",
    "            else:\n",
    "                episodes.append([item])\n",
    "            prev_slot = slot\n",
    "        return episodes\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'TaskData(task={}, num_train={}, num_test={})'.format(self.task, len(self.train), len(self.test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskData(task=1, num_train=200, num_test=200)\n",
      "  train_file = babi-tasks_1-20_v1-2/en/qa1_single-supporting-fact_train.txt\n",
      "  test_file  = babi-tasks_1-20_v1-2/en/qa1_single-supporting-fact_test.txt\n",
      "\n",
      "S[01](text=['mary', 'moved', 'to', 'the', 'bathroom'])\n",
      "S[02](text=['john', 'went', 'to', 'the', 'hallway'])\n",
      "Q[03](text=['where', 'is', 'mary'], answer=['bathroom'], refs=[1])\n",
      "S[04](text=['daniel', 'went', 'back', 'to', 'the', 'hallway'])\n",
      "S[05](text=['sandra', 'moved', 'to', 'the', 'garden'])\n",
      "Q[06](text=['where', 'is', 'daniel'], answer=['hallway'], refs=[4])\n",
      "S[07](text=['john', 'moved', 'to', 'the', 'office'])\n",
      "S[08](text=['sandra', 'journeyed', 'to', 'the', 'bathroom'])\n",
      "Q[09](text=['where', 'is', 'daniel'], answer=['hallway'], refs=[4])\n",
      "S[10](text=['mary', 'moved', 'to', 'the', 'hallway'])\n",
      "S[11](text=['daniel', 'travelled', 'to', 'the', 'office'])\n",
      "Q[12](text=['where', 'is', 'daniel'], answer=['office'], refs=[11])\n",
      "S[13](text=['john', 'went', 'back', 'to', 'the', 'garden'])\n",
      "S[14](text=['john', 'moved', 'to', 'the', 'bedroom'])\n",
      "Q[15](text=['where', 'is', 'sandra'], answer=['bathroom'], refs=[8])\n"
     ]
    }
   ],
   "source": [
    "data = TaskData(1)\n",
    "print(data)\n",
    "print('  train_file =', data.train_file)\n",
    "print('  test_file  =', data.test_file)\n",
    "print()\n",
    "for x in data.train[0]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab\n",
      "0 => mary\n",
      "1 => moved\n",
      "2 => to\n",
      "3 => the\n",
      "4 => bathroom\n",
      "5 => john\n",
      "6 => went\n",
      "7 => hallway\n",
      "8 => where\n",
      "9 => is\n",
      "10 => daniel\n",
      "11 => back\n",
      "12 => sandra\n",
      "13 => garden\n",
      "14 => office\n",
      "15 => journeyed\n",
      "16 => travelled\n",
      "17 => bedroom\n",
      "18 => kitchen\n"
     ]
    }
   ],
   "source": [
    "word2id = {}\n",
    "id2word = {}\n",
    "for episode in data.train + data.test:\n",
    "    for item in episode:\n",
    "        for word in item.text + (item.answer if isinstance(item, Query) else []):\n",
    "            try:\n",
    "                i = word2id[word]\n",
    "            except KeyError:\n",
    "                word2id[word] = len(word2id)\n",
    "                id2word[word2id[word]] = word\n",
    "print('Vocab')\n",
    "for i, word in sorted(id2word.items()):\n",
    "    print(i, '=>', word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Network\n",
    "\n",
    "### Update\n",
    "$\\begin{align*}\n",
    "    v &= Ax_t \\\\\n",
    "    z &= \\sigma(W_a v + b_a) \\\\\n",
    "    s_t &= \\text{lstm}(v, s_{t-1}) \\\\\n",
    "    g &= \\text{softmax}(W_g s_t^h + b_g) \\\\\n",
    "    m_{i,t} &= g_i \\cdot z + (1 - g_i) * m_{i,t-1}\n",
    "\\end{align*}$\n",
    "\n",
    "### Answer\n",
    "$\\begin{align*}\n",
    "    v &= Aq_t \\\\\n",
    "    k &= \\sigma(W_k v + b_k) \\\\\n",
    "    g_i &= \\frac{k^T m_{i,t}}{||k||\\cdot||m_{i,t-1}||} \\\\\n",
    "    h_t &= \\sum_i g_i \\cdot m_{i,t-1}\n",
    "\\end{align*}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.w = Parameter(FloatTensor(n_in + n_out, 4 * n_out))\n",
    "        self.b = Parameter(FloatTensor(1, 4 * n_out))\n",
    "        self.h0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.c0 = Parameter(FloatTensor(1, n_out))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.w.data.normal_(0, 0.01)\n",
    "        self.b.data.zero_()\n",
    "        self.h0.data.zero_()\n",
    "        self.c0.data.zero_()\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self.h0, self.c0\n",
    "    \n",
    "    def observable(self, s):\n",
    "        return s[0]\n",
    "    \n",
    "    def step(self, x, s=None):\n",
    "        h_prev, c_prev = s or self.initial_state\n",
    "        z = torch.cat([x, h_prev], 1)\n",
    "        a = z.mm(self.w) + self.b.expand(x.size(0), self.b.size(1))\n",
    "        i, f, o, g = torch.chunk(a, 4, dim=1)\n",
    "        i = F.sigmoid(i)\n",
    "        f = F.sigmoid(f)\n",
    "        o = F.sigmoid(o)\n",
    "        g = F.tanh(g)\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * c\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self, n_words, embed_dim, controller_hid_dim, register_dim, n_registers):\n",
    "        super(RegNet, self).__init__()\n",
    "        self.n_words = n_words\n",
    "        self.embed_dim = embed_dim\n",
    "        self.controller_hid_dim = controller_hid_dim\n",
    "        self.register_dim = register_dim\n",
    "        self.n_registers = n_registers\n",
    "        \n",
    "        self.embedding = Embedding(n_words, embed_dim)\n",
    "        self.candidate = Linear(embed_dim, register_dim)\n",
    "        self.controller = LSTM(embed_dim, controller_hid_dim)\n",
    "        self.attend = Linear(controller_hid_dim, n_registers)\n",
    "        self.read_key = Linear(embed_dim, register_dim)\n",
    "        self.output = Linear(register_dim, n_words)\n",
    "    \n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        memory = [Variable(torch.zeros(1, self.register_dim)) for i in range(self.n_registers)]\n",
    "        return (memory, self.controller.initial_state)\n",
    "    \n",
    "    def embed(self, x):\n",
    "        return self.embedding(x).sum(0)\n",
    "    \n",
    "    def update(self, x, state=None):\n",
    "        m, s = state or self.initial_state\n",
    "        v = self.embed(x)\n",
    "        z = F.sigmoid(self.candidate(v))\n",
    "        s = self.controller.step(v, s)\n",
    "        g = F.softmax(self.attend(self.controller.observable(s)))\n",
    "        g = [gi.expand(z.size()) for gi in g.chunk(self.n_registers, dim=1)]\n",
    "        m = [g[i] * z + (1 - g[i]) * m[i] for i in range(self.n_registers)]\n",
    "        return m, s\n",
    "    \n",
    "    def scores(self, x, s=None):\n",
    "        m, _ = s or self.initial_state\n",
    "        v = self.embed(x)\n",
    "        k = self.read_key(v)\n",
    "        k_norm = k.norm()\n",
    "        g = [m[i].dot(k) / (m[i].norm() * k_norm) for i in range(self.n_registers)]\n",
    "        g = [g[i].unsqueeze(0).expand(m[i].size()) for i in range(self.n_registers)]\n",
    "        h = sum(g[i] * m[i] for i in range(self.n_registers))\n",
    "        return self.output(h)\n",
    "        \n",
    "    def unfold(self, xs):\n",
    "        s = self.initial_state\n",
    "        ss = []\n",
    "        ps = []\n",
    "        for x in xs:\n",
    "            if isinstance(x, Statement):\n",
    "                s = self.update(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(None)\n",
    "            elif isinstance(x, Query):\n",
    "                p = self.scores(x.text, s)\n",
    "                ss.append(s)\n",
    "                ps.append(p)\n",
    "            else:\n",
    "                raise TypeError('expected Statement or Query, got {}'.format(type(x)))\n",
    "        return ps, ss\n",
    "\n",
    "    def is_output(self, p, x):\n",
    "        if p is None:\n",
    "            assert isinstance(x, Statement)\n",
    "            return False\n",
    "        assert isinstance(x, Query)\n",
    "        return True\n",
    "    \n",
    "    def answer_cost(self, p, x):\n",
    "        return F.cross_entropy(p, x.answer)\n",
    "    \n",
    "    def cost(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return sum(self.answer_cost(p, x) \n",
    "                   for p, x in zip(ps, xs) \n",
    "                       if self.is_output(p, x))\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        ps, _ = self.unfold(xs)\n",
    "        return [p.data.numpy().argmax(1) \n",
    "                if self.is_output(p, x) \n",
    "                else None \n",
    "                for p, x in zip(ps, xs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regnet = RegNet(len(word2id), 20, 15, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 200\n",
      "2019.81519651\n",
      "1688.50849533\n",
      "1505.36831737\n",
      "1394.07288146\n",
      "1304.93501854\n",
      "1245.51178932\n",
      "1211.32668853\n",
      "1182.7722156\n",
      "1160.56629539\n",
      "1135.86292756\n",
      "1123.11780107\n",
      "1104.13347006\n",
      "1092.08082724\n",
      "1101.46472955\n",
      "1093.65085626\n",
      "1083.36482334\n",
      "1087.56319308\n",
      "1074.16418105\n",
      "1069.72428298\n",
      "1058.95768261\n",
      "1062.40102416\n",
      "1059.79730749\n",
      "1045.54559696\n",
      "1044.84016967\n",
      "1013.67597759\n",
      "974.118311048\n",
      "920.633042693\n",
      "878.022991657\n",
      "838.997856259\n",
      "807.104522824\n",
      "778.487491727\n",
      "748.365551949\n",
      "719.048949778\n",
      "676.36352545\n",
      "646.833854616\n",
      "626.400753856\n",
      "588.101940274\n",
      "538.134019911\n",
      "498.6312747\n",
      "467.582735419\n",
      "441.136835396\n",
      "418.767855883\n",
      "396.122953534\n",
      "379.045443714\n",
      "367.836013973\n",
      "356.14786762\n",
      "347.692258805\n",
      "340.22368452\n",
      "335.874804467\n",
      "329.50463146\n",
      "324.056122273\n",
      "316.782067686\n",
      "312.514947042\n",
      "309.623082504\n",
      "305.949044272\n",
      "302.717185125\n",
      "298.643917307\n",
      "297.692042604\n",
      "291.593903109\n",
      "286.751051918\n",
      "271.134983495\n",
      "234.063230202\n",
      "200.039684802\n",
      "180.252600722\n",
      "164.541784376\n",
      "146.013142951\n",
      "126.340037674\n",
      "108.903952651\n",
      "94.7894595414\n",
      "85.0233711153\n",
      "76.6198118627\n",
      "69.9645889029\n",
      "65.1258685961\n",
      "60.4871681929\n",
      "56.8358394131\n",
      "53.3986843675\n",
      "50.57047005\n",
      "48.0698486641\n",
      "45.8765407726\n",
      "43.8812095821\n",
      "42.0892032087\n",
      "40.3306195885\n",
      "38.8783667833\n",
      "37.4140284583\n",
      "36.1707600355\n",
      "34.926525984\n",
      "33.8141023554\n",
      "32.6789672896\n",
      "31.7446372807\n",
      "30.7912905365\n",
      "29.9562619664\n",
      "29.1029616334\n",
      "28.3316960074\n",
      "27.5878685787\n",
      "26.9199062586\n",
      "26.2381388284\n",
      "25.6390825696\n",
      "25.0125194527\n",
      "24.4334514663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-38b8bac4bdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/thom/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/blas.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mgrad_matrix2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mgrad_matrix2\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_train = [[x.torchify(word2id) for x in xs] for xs in data.train]\n",
    "print('Number of samples:', len(data_train))\n",
    "while True:\n",
    "    random.shuffle(data_train)\n",
    "    sum_nll = 0.0\n",
    "    for xs in data_train:\n",
    "        regnet.zero_grad()\n",
    "        nll = regnet.cost(xs)\n",
    "        nll.backward()\n",
    "        for param in regnet.parameters():\n",
    "            param.data.add_(-0.005, param.grad.data)\n",
    "        sum_nll += nll.data.numpy()[0]\n",
    "    print(sum_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S[01](text=['john', 'travelled', 'to', 'the', 'hallway']) None\n",
      "S[02](text=['mary', 'journeyed', 'to', 'the', 'bathroom']) None\n",
      "Q[03](text=['where', 'is', 'john'], answer=['hallway'], refs=[1])\n",
      "(['hallway'], [7]) (['hallway'], array([7]))\n",
      "S[04](text=['daniel', 'went', 'back', 'to', 'the', 'bathroom']) None\n",
      "S[05](text=['john', 'moved', 'to', 'the', 'bedroom']) None\n",
      "Q[06](text=['where', 'is', 'mary'], answer=['bathroom'], refs=[2])\n",
      "(['bathroom'], [4]) (['bathroom'], array([4]))\n",
      "S[07](text=['john', 'went', 'to', 'the', 'hallway']) None\n",
      "S[08](text=['sandra', 'journeyed', 'to', 'the', 'kitchen']) None\n",
      "Q[09](text=['where', 'is', 'sandra'], answer=['kitchen'], refs=[8])\n",
      "(['kitchen'], [18]) (['kitchen'], array([18]))\n",
      "S[10](text=['sandra', 'travelled', 'to', 'the', 'hallway']) None\n",
      "S[11](text=['john', 'went', 'to', 'the', 'garden']) None\n",
      "Q[12](text=['where', 'is', 'sandra'], answer=['hallway'], refs=[10])\n",
      "(['hallway'], [7]) (['hallway'], array([7]))\n",
      "S[13](text=['sandra', 'went', 'back', 'to', 'the', 'bathroom']) None\n",
      "S[14](text=['sandra', 'moved', 'to', 'the', 'kitchen']) None\n",
      "Q[15](text=['where', 'is', 'sandra'], answer=['kitchen'], refs=[14])\n",
      "(['kitchen'], [18]) (['kitchen'], array([18]))\n",
      "S[01](text=['sandra', 'travelled', 'to', 'the', 'kitchen']) None\n",
      "S[02](text=['sandra', 'travelled', 'to', 'the', 'hallway']) None\n",
      "Q[03](text=['where', 'is', 'sandra'], answer=['hallway'], refs=[2])\n",
      "(['hallway'], [7]) (['hallway'], array([7]))\n",
      "S[04](text=['mary', 'went', 'to', 'the', 'bathroom']) None\n",
      "S[05](text=['sandra', 'moved', 'to', 'the', 'garden']) None\n",
      "Q[06](text=['where', 'is', 'sandra'], answer=['garden'], refs=[5])\n",
      "(['garden'], [13]) (['garden'], array([13]))\n",
      "S[07](text=['sandra', 'travelled', 'to', 'the', 'office']) None\n",
      "S[08](text=['daniel', 'journeyed', 'to', 'the', 'hallway']) None\n",
      "Q[09](text=['where', 'is', 'daniel'], answer=['hallway'], refs=[8])\n",
      "(['hallway'], [7]) (['hallway'], array([7]))\n",
      "S[10](text=['daniel', 'journeyed', 'to', 'the', 'office']) None\n",
      "S[11](text=['john', 'moved', 'to', 'the', 'hallway']) None\n",
      "Q[12](text=['where', 'is', 'sandra'], answer=['office'], refs=[7])\n",
      "(['office'], [14]) (['office'], array([14]))\n",
      "S[13](text=['john', 'travelled', 'to', 'the', 'bathroom']) None\n",
      "S[14](text=['john', 'journeyed', 'to', 'the', 'office']) None\n",
      "Q[15](text=['where', 'is', 'daniel'], answer=['office'], refs=[10])\n",
      "(['office'], [14]) (['office'], array([14]))\n"
     ]
    }
   ],
   "source": [
    "for i, xs in enumerate(data.test):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    xs_vars = [x.torchify(word2id) for x in xs]\n",
    "    ps = regnet.predict(xs_vars)\n",
    "    assert(len(ps) == len(xs))\n",
    "    for x, p in zip(xs, ps):\n",
    "        if p is None:\n",
    "            print(x, None)\n",
    "        else:\n",
    "            print(x)\n",
    "            print((x.answer, [word2id[w] for w in x.answer]),\n",
    "                  ([id2word[j] for j in p.tolist()], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(ds):\n",
    "    errors = 0.0\n",
    "    total = 0.0\n",
    "    for xs in ds:\n",
    "        xs_vars = [x.torchify(word2id) for x in xs]\n",
    "        ps = regnet.predict(xs_vars)\n",
    "        assert(len(ps) == len(xs))\n",
    "        for x, p in zip(xs, ps):\n",
    "            if p is not None:\n",
    "                if x.answer != [id2word[i] for i in p.tolist()]:\n",
    "                    errors += 1\n",
    "                total += 1\n",
    "    print(errors, total)\n",
    "    return errors, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error(data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
